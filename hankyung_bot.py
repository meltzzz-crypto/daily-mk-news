import os
import time
import requests
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup

# Configuration
WEBHOOK_URL = os.environ.get("DISCORD_WEBHOOK_URL")
TARGET_URL = "https://www.hankyung.com/mr"

def setup_driver():
    chrome_options = Options()
    chrome_options.add_argument("--headless")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
    
    driver = webdriver.Chrome(options=chrome_options)
    return driver

def get_article_summary(driver, url):
    try:
        driver.get(url)
        time.sleep(2) # ì¶©ë¶„íˆ ë¡œë”© ëŒ€ê¸°
        
        soup = BeautifulSoup(driver.page_source, "html.parser")
        content_element = soup.select_one("#articletxt") or soup.select_one(".article-body") or soup.select_one(".article_body") or soup.select_one("#article-body")
        
        if not content_element:
            return None
            
        text = content_element.get_text(separator="\n").strip()
        sentences = text.split('.')
        
        summary = []
        for s in sentences:
            s = s.strip()
            if len(s) > 30 and "ê¸°ì" not in s and "ì´ë©”ì¼" not in s and "â“’" not in s:
                summary.append(s + '.')
                if len(summary) >= 3:
                    break
        return summary
    except:
        return None

def fetch_hankyung_mr():
    print(f"ğŸ” [1/3] ì ‘ì† ì‹œë„ ì¤‘: {TARGET_URL}")
    driver = setup_driver()
    data = {"youtube_link": None, "articles": []}
    
    try:
        driver.get(TARGET_URL)
        time.sleep(5) # í˜ì´ì§€ê°€ ì™„ì „íˆ ëœ° ë•Œê¹Œì§€ ë„‰ë„‰íˆ ëŒ€ê¸°
        
        # í™”ë©´ì„ ì•„ë˜ë¡œ ì‚´ì§ ë‚´ë¦¬ê¸° (ë°ì´í„° ë¡œë”© ìœ ë„)
        driver.execute_script("window.scrollTo(0, 500);")
        time.sleep(2)

        soup = BeautifulSoup(driver.page_source, "html.parser")
        
        # 1. ìœ íŠœë¸Œ ë§í¬ ì°¾ê¸°
        links = soup.find_all("a", href=True)
        for a in links:
            href = a['href']
            if "youtube.com/watch" in href or "youtu.be" in href:
                data["youtube_link"] = href
                break
        print(f"ğŸ“º ìœ íŠœë¸Œ ë§í¬ ì°¾ìŒ: {data['youtube_link']}")

        # 2. ê¸°ì‚¬ ì°¾ê¸° (ê°€ì¥ ê°•ë ¥í•œ ë°©ì‹)
        print("ğŸ•µï¸ [2/3] ê¸°ì‚¬ ëª©ë¡ ê²€ìƒ‰ ì¤‘...")
        
        article_candidates = []
        # 'ì˜¤ëŠ˜ì˜ ê¸°ì‚¬' í…ìŠ¤íŠ¸ ì£¼ë³€ì—ì„œ ì°¾ê¸°
        headers = soup.find_all(string=lambda t: t and "ì˜¤ëŠ˜ì˜ ê¸°ì‚¬" in t)
        
        if headers:
            print("âœ… 'ì˜¤ëŠ˜ì˜ ê¸°ì‚¬' ì„¹ì…˜ ë°œê²¬!")
            # í•´ë‹¹ ì„¹ì…˜ ì£¼ë³€ì˜ ëª¨ë“  ë§í¬ ìˆ˜ì§‘
            parent = headers[0].parent
            for _ in range(6): # ìœ„ë¡œ 6ë‹¨ê³„ê¹Œì§€ ì˜¬ë¼ê°€ë©° ì»¨í…Œì´ë„ˆ ê²€ìƒ‰
                if parent:
                    found_links = parent.find_all("a", href=True)
                    for l in found_links:
                        url = l['href']
                        title = l.get_text(strip=True)
                        if "/article/" in url and len(title) > 10:
                            if not url.startswith("http"): url = "https://www.hankyung.com" + url
                            article_candidates.append({"title": title, "url": url})
                parent = parent.parent if parent else None
        
        # ë§Œì•½ ì„¹ì…˜ìœ¼ë¡œ ëª»ì°¾ì•˜ë‹¤ë©´, í˜ì´ì§€ ì „ì²´ì—ì„œ ë‰´ìŠ¤ì²˜ëŸ¼ ë³´ì´ëŠ” ë§í¬ ë‹¤ ê¸ì–´ì˜¤ê¸° (ìµœí›„ì˜ ë³´ë£¨)
        if not article_candidates:
            print("âš ï¸ ì„¹ì…˜ì„ ëª» ì°¾ì•„ ì „ì²´ í˜ì´ì§€ì—ì„œ ê²€ìƒ‰í•©ë‹ˆë‹¤.")
            for l in links:
                url = l['href']
                title = l.get_text(strip=True)
                if "/article/" in url and len(title) > 15:
                    if not url.startswith("http"): url = "https://www.hankyung.com" + url
                    article_candidates.append({"title": title, "url": url})

        # ì¤‘ë³µ ì œê±° ë° ìƒìœ„ 10ê°œë§Œ ì„ ì •
        seen = set()
        final_articles = []
        for art in article_candidates:
            if art['url'] not in seen:
                final_articles.append(art)
                seen.add(art['url'])
                if len(final_articles) >= 10: break
        
        print(f"ğŸ“ [3/3] ê¸°ì‚¬ {len(final_articles)}ê°œ ë°œê²¬! ìš”ì•½ ì‹œì‘...")
        
        for art in final_articles:
            print(f"   - {art['title'][:20]}... ìš”ì•½ ì¤‘")
            art['summary'] = get_article_summary(driver, art['url'])
            
        data["articles"] = final_articles
        
    except Exception as e:
        print(f"âŒ ì—ëŸ¬ ë°œìƒ: {e}")
    finally:
        driver.quit()
    return data

def send_to_discord(data):
    if not WEBHOOK_URL or not WEBHOOK_URL.startswith("http"):
        print("âŒ ì—ëŸ¬: ë””ìŠ¤ì½”ë“œ ì›¹í›… ì£¼ì†Œê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ í‹€ë¦½ë‹ˆë‹¤!")
        return
        
    articles = data["articles"]
    if not articles:
        print("ğŸ˜¿ ë³´ë‚¼ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
        
    print(f"ğŸš€ ë””ìŠ¤ì½”ë“œë¡œ ìŠ! ({len(articles)}ê°œ)")
    
    # ì²« ë²ˆì§¸ ë©”ì‹œì§€ (ì œëª© ë° ìœ íŠœë¸Œ)
    header = {
        "title": "â˜• í•œê²½ ëª¨ë‹ë£¨í‹´ ë¸Œë¦¬í•‘",
        "description": f"ğŸ—“ï¸ {datetime.now().strftime('%Y-%m-%d')}\n" + (f"ğŸ“º [ë¼ì´ë¸Œ ë°©ì†¡]({data['youtube_link']})" if data['youtube_link'] else ""),
        "color": 0x1E90FF,
        "url": TARGET_URL
    }
    
    embed_list = [header]
    for i, art in enumerate(articles):
        summary = "\n".join([f"â€¢ {s}" for s in art['summary']]) if art.get('summary') else "ë§í¬ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”."
        embed_list.append({
            "title": f"{i+1}. {art['title']}",
            "url": art['url'],
            "description": summary,
            "color": 0xFFFFFF
        })
        
        if len(embed_list) == 10:
            requests.post(WEBHOOK_URL, json={"embeds": embed_list})
            embed_list = []
            time.sleep(1)
            
    if embed_list:
        requests.post(WEBHOOK_URL, json={"embeds": embed_list})
    print("âœ¨ ì „ì†¡ ì™„ë£Œ!")

if __name__ == "__main__":
    results = fetch_hankyung_mr()
    send_to_discord(results)
